{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, getpass\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "_set_env(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_set_env(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"langchain-academy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smart_scraper_func(openai_key: str, prompt: str, source: str):\n",
    "    \"\"\"\n",
    "    Performs intelligent scraping using SmartScraperGraph.\n",
    "\n",
    "    Parameters:\n",
    "    openai_key (str): The OpenAI API key.\n",
    "    prompt (str): The prompt to use for scraping.\n",
    "    source (str): The source from which to perform scraping.\n",
    "\n",
    "    Returns:\n",
    "    dict: The result of the scraping in JSON format.\n",
    "\n",
    "    Example:\n",
    "    >>> result = smart_scraper_func('your_openai_key', 'Extract article titles', 'https://example.com')\n",
    "    >>> print(result)\n",
    "    \"\"\"\n",
    "    import json\n",
    "    from scrapegraphai.graphs import SmartScraperGraph\n",
    "\n",
    "    graph_config = {\n",
    "        \"llm\": {\n",
    "            \"api_key\": openai_key,\n",
    "            \"model\": \"openai/gpt-4o\",\n",
    "        },\n",
    "        \"verbose\": True,\n",
    "        \"headless\": False,\n",
    "    }\n",
    "\n",
    "    smart_scraper_graph = SmartScraperGraph(\n",
    "        prompt=prompt,\n",
    "        source=source,\n",
    "        config=graph_config\n",
    "    )\n",
    "\n",
    "    result = smart_scraper_graph.run()\n",
    "    print(json.dumps(result, indent=4))\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_graph_func(key: str, query: str):\n",
    "    \"\"\"\n",
    "    Performs a search using SearchGraph.\n",
    "\n",
    "    Parameters:\n",
    "    key (str): The OpenAI API key.\n",
    "    query (str): The search query to use.\n",
    "\n",
    "    Returns:\n",
    "    dict: The result of the search.\n",
    "\n",
    "    Example:\n",
    "    >>> result = search_graph_func('your_openai_key', 'example search')\n",
    "    >>> print(result)\n",
    "    \"\"\"\n",
    "    from scrapegraphai.graphs import SearchGraph\n",
    "\n",
    "    graph_config = {\n",
    "        \"llm\": {\n",
    "            \"api_key\": key,\n",
    "            \"model\": \"openai/gpt-4o\",\n",
    "        },\n",
    "        \"max_results\": 2,\n",
    "        \"verbose\": True,\n",
    "    }\n",
    "\n",
    "    search_graph = SearchGraph(\n",
    "        prompt=query,\n",
    "        config=graph_config\n",
    "    )\n",
    "\n",
    "    result = search_graph.run()\n",
    "    print(result)\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "tools = [smart_scraper_func, search_graph_func]\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "llm_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import MessagesState\n",
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
    "\n",
    "sys_msg = SystemMessage(content=\"You are a helpful assistant tasked with performing scraping scripts with scrapegraphai\")\n",
    "\n",
    "def assistant(state: MessagesState):\n",
    "   return {\"messages\": [llm_with_tools.invoke([sys_msg] + state[\"messages\"])]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import START, StateGraph\n",
    "\n",
    "builder = StateGraph(MessagesState)\n",
    "\n",
    "memory = MemorySaver()\n",
    "react_graph_memory = builder.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Specify an input\n",
    "messages = [HumanMessage(content=\"Add 3 and 4.\")]\n",
    "\n",
    "# Run\n",
    "messages = react_graph_memory.invoke({\"messages\": messages},config)\n",
    "for m in messages['messages']:\n",
    "    m.pretty_print()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
